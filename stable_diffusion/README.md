# Stable Diffusion - PyTorch
PyTorch implementation of Stable Diffusion from scratch

Try using `demo.ipynb` to generate images!  
</br>

## Download Model
Download `v1-5-pruned-emaonly.ckpt` from
[This](https://huggingface.co/runwayml/stable-diffusion-v1-5/tree/main)
and save it in the data folder  
</br>
</br>

# Reference

## Paper
- [Stable Diffusion](https://arxiv.org/abs/2112.10752)
- [VAE](https://arxiv.org/abs/1312.6114)
- [CLIP](https://arxiv.org/abs/2103.00020)
- [U-Net](https://arxiv.org/abs/1505.04597)
- [Attention](https://arxiv.org/abs/1706.03762)
- [Self Attention](https://arxiv.org/abs/1812.07860v1)
- [Cross Attention](https://arxiv.org/abs/2103.14899)
- [Classifier Free Guidance](https://arxiv.org/abs/2207.12598)
- [DDPM(Denoising Diffusion Probabilistic Models)](https://arxiv.org/abs/2006.11239)
</br>

## Github
- [SouceCode at 'This stable diffusion code'](https://github.com/hkproj/pytorch-stable-diffusion)
- [Original Stable Diffusion](https://github.com/CompVis/stable-diffusion)
- [CLIP(Contrastive Languageâ€“Image Pre-training)](https://github.com/openai/CLIP)  
</br>

## Appendix
![Stable Diffusion(Text-To-Image)](images/Text-To-Image.png)
![Stable Diffusion(Image-To-Image)](images/Image-To-Image.png)
![VAE](images/VAE.png)
![CLIP](images/CLIP.png)
![U-Net](images/U-Net.png)  